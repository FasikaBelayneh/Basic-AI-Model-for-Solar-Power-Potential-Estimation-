{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf1bf0e-b682-4ce9-971a-fa9d7e43cd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "| Year   | Month   | Avg_Temp (°C)   | Max_Temp (°C)   | Min_Temp (°C)   | Precipitation (mm)   | Humidity (%)      | Wind_Speed (m/s)   | Solar_Irradiance (W/m²)   | Cloud_Cover (%)   | CO2_Concentration (ppm)   | Latitude   | Longitude   | Altitude (m)   | Proximity_to_Water (km)   | Urbanization_Index   | Vegetation_Index   | ENSO_Index   | Particulate_Matter (µg/m³)   | Sea_Surface_Temp (°C)   |\n",
      "|:-------|:--------|:----------------|:----------------|:----------------|:---------------------|:------------------|:-------------------|:--------------------------|:------------------|:--------------------------|:-----------|:------------|:---------------|:--------------------------|:---------------------|:-------------------|:-------------|:-----------------------------|:------------------------|\n",
      "| nan    | 1       | -3.46052        | 33.0569         | nan             | 184.9                | 89.62081302618182 | 9.74289            | nan                       | 58.5308           | nan                       | 40.7128    | nan         | 10             | 15                        | nan                  | 0.0442378          | 0.633694     | 33.4371                      | 18.5454                 |\n",
      "| 2020   | 2       | nan             | 25.9019         | 3.17397         | 2.95724              | 95.17102000342224 | 10.6482            | 252.314                   | 32.8567           | 419.596                   | 40.7128    | -74.006     | 10             | 15                        | 99999                | 0.61284            | nan          | 24.5048                      | 15.9096                 |\n",
      "| 2020   | 3       | 7.86984         | 18.6342         | 10.4249         | nan                  | nan               | nan                | 247.391                   | 29.3802           | 416.65                    | 40.7128    | -74.006     | 10             | 15                        | 0.341732             | 0.466565           | -0.428058    | 32.3275                      | 21.2811                 |\n",
      "| nan    | 4       | -0.0498626      | 13.0306         | -9.19643        | 102.454              | Unknown           | 0.898698           | 143.262                   | 17.4969           | 418.923                   | 40.7128    | -74.006     | 10             | 15                        | 0.896383             | 0.0304659          | -0.570708    | 20.4963                      | nan                     |\n",
      "| 2020   | 5       | 19.8951         | 35.8821         | 20.068          | 185.729              | 73.99994640624561 | 13.1283            | 169.549                   | 2.19371           | 401.897                   | 40.7128    | -74.006     | 10             | 99999                     | 0.0761732            | nan                | -0.286149    | 22.6491                      | 15.503                  |\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 20 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Year                        48 non-null     object \n",
      " 1   Month                       48 non-null     object \n",
      " 2   Avg_Temp (°C)               46 non-null     float64\n",
      " 3   Max_Temp (°C)               46 non-null     object \n",
      " 4   Min_Temp (°C)               45 non-null     object \n",
      " 5   Precipitation (mm)          49 non-null     object \n",
      " 6   Humidity (%)                45 non-null     object \n",
      " 7   Wind_Speed (m/s)            51 non-null     object \n",
      " 8   Solar_Irradiance (W/m²)     48 non-null     object \n",
      " 9   Cloud_Cover (%)             49 non-null     object \n",
      " 10  CO2_Concentration (ppm)     47 non-null     float64\n",
      " 11  Latitude                    47 non-null     object \n",
      " 12  Longitude                   50 non-null     object \n",
      " 13  Altitude (m)                49 non-null     object \n",
      " 14  Proximity_to_Water (km)     47 non-null     object \n",
      " 15  Urbanization_Index          50 non-null     float64\n",
      " 16  Vegetation_Index            50 non-null     object \n",
      " 17  ENSO_Index                  50 non-null     object \n",
      " 18  Particulate_Matter (µg/m³)  50 non-null     object \n",
      " 19  Sea_Surface_Temp (°C)       46 non-null     object \n",
      "dtypes: float64(3), object(17)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_dataset_file.csv' with the actual name of the file you downloaded\n",
    "try:\n",
    "    df = pd.read_csv('climate_change_dataset.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    # Display the first 5 rows to get a glimpse of the data\n",
    "    print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "    # Display basic information about the dataset\n",
    "    print(\"\\nDataset Info:\")\n",
    "    df.info()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'your_dataset_file.csv' is in the correct directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93417a97-930b-4a9b-b552-d8580d2f7aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of missing values per column:\n",
      "|                            | 0   |\n",
      "|:---------------------------|:----|\n",
      "| Year                       | 5   |\n",
      "| Month                      | 5   |\n",
      "| Avg_Temp (°C)              | 7   |\n",
      "| Max_Temp (°C)              | 7   |\n",
      "| Min_Temp (°C)              | 8   |\n",
      "| Precipitation (mm)         | 4   |\n",
      "| Humidity (%)               | 8   |\n",
      "| Wind_Speed (m/s)           | 2   |\n",
      "| Solar_Irradiance (W/m²)    | 5   |\n",
      "| Cloud_Cover (%)            | 4   |\n",
      "| CO2_Concentration (ppm)    | 6   |\n",
      "| Latitude                   | 6   |\n",
      "| Longitude                  | 3   |\n",
      "| Altitude (m)               | 4   |\n",
      "| Proximity_to_Water (km)    | 6   |\n",
      "| Urbanization_Index         | 3   |\n",
      "| Vegetation_Index           | 3   |\n",
      "| ENSO_Index                 | 3   |\n",
      "| Particulate_Matter (µg/m³) | 3   |\n",
      "| Sea_Surface_Temp (°C)      | 7   |\n",
      "\n",
      "Missing values per column after imputation:\n",
      "|                            | 0   |\n",
      "|:---------------------------|:----|\n",
      "| Year                       | 0   |\n",
      "| Month                      | 0   |\n",
      "| Avg_Temp (°C)              | 0   |\n",
      "| Max_Temp (°C)              | 0   |\n",
      "| Min_Temp (°C)              | 0   |\n",
      "| Precipitation (mm)         | 0   |\n",
      "| Humidity (%)               | 0   |\n",
      "| Wind_Speed (m/s)           | 0   |\n",
      "| Solar_Irradiance (W/m²)    | 0   |\n",
      "| Cloud_Cover (%)            | 0   |\n",
      "| CO2_Concentration (ppm)    | 0   |\n",
      "| Latitude                   | 0   |\n",
      "| Longitude                  | 0   |\n",
      "| Altitude (m)               | 0   |\n",
      "| Proximity_to_Water (km)    | 0   |\n",
      "| Urbanization_Index         | 0   |\n",
      "| Vegetation_Index           | 0   |\n",
      "| ENSO_Index                 | 0   |\n",
      "| Particulate_Matter (µg/m³) | 0   |\n",
      "| Sea_Surface_Temp (°C)      | 0   |\n",
      "\n",
      "First 5 rows after imputation:\n",
      "| Year    | Month   | Avg_Temp (°C)   | Max_Temp (°C)   | Min_Temp (°C)   | Precipitation (mm)   | Humidity (%)   | Wind_Speed (m/s)   | Solar_Irradiance (W/m²)   | Cloud_Cover (%)   | CO2_Concentration (ppm)   | Latitude   | Longitude   | Altitude (m)   | Proximity_to_Water (km)   | Urbanization_Index   | Vegetation_Index   | ENSO_Index   | Particulate_Matter (µg/m³)   | Sea_Surface_Temp (°C)   |\n",
      "|:--------|:--------|:----------------|:----------------|:----------------|:---------------------|:---------------|:-------------------|:--------------------------|:------------------|:--------------------------|:-----------|:------------|:---------------|:--------------------------|:---------------------|:-------------------|:-------------|:-----------------------------|:------------------------|\n",
      "| 2021.87 | 1       | -3.46052        | 33.0569         | 2280.9          | 184.9                | 89.6208        | 9.74289            | 173.826                   | 58.5308           | 423.476                   | 40.7128    | -74.006     | 10             | 15                        | 4000.48              | 0.0442378          | 0.633694     | 33.4371                      | 18.5454                 |\n",
      "| 2020    | 2       | 13.0187         | 25.9019         | 3.17397         | 2.95724              | 95.171         | 10.6482            | 252.314                   | 32.8567           | 419.596                   | 40.7128    | -74.006     | 10             | 15                        | 99999                | 0.61284            | 4081.67      | 24.5048                      | 15.9096                 |\n",
      "| 2020    | 3       | 7.86984         | 18.6342         | 10.4249         | 2188.91              | 67.2697        | 2008.36            | 247.391                   | 29.3802           | 416.65                    | 40.7128    | -74.006     | 10             | 15                        | 0.341732             | 0.466565           | -0.428058    | 32.3275                      | 21.2811                 |\n",
      "| 2021.87 | 4       | -0.0498626      | 13.0306         | -9.19643        | 102.454              | 67.2697        | 0.898698           | 143.262                   | 17.4969           | 418.923                   | 40.7128    | -74.006     | 10             | 15                        | 0.896383             | 0.0304659          | -0.570708    | 20.4963                      | 19.5453                 |\n",
      "| 2020    | 5       | 19.8951         | 35.8821         | 20.068          | 185.729              | 73.9999        | 13.1283            | 169.549                   | 2.19371           | 401.897                   | 40.7128    | -74.006     | 10             | 99999                     | 0.0761732            | 0.441901           | -0.286149    | 22.6491                      | 15.503                  |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is the DataFrame you loaded initially\n",
    "\n",
    "print(\"Original number of missing values per column:\")\n",
    "print(df.isnull().sum().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Create a copy of the DataFrame\n",
    "df_imputed = df.copy()\n",
    "\n",
    "# Identify numerical columns for imputation\n",
    "numerical_cols = df_imputed.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Impute missing values in numerical columns with the mean\n",
    "for col in numerical_cols:\n",
    "    if df_imputed[col].isnull().any(): # Check if the column actually has missing values\n",
    "        mean_val = df_imputed[col].mean()\n",
    "        df_imputed[col] = df_imputed[col].fillna(mean_val) # Avoids the Future Warning\n",
    "\n",
    "# For columns that might be read as 'object' but contain numbers (like 'Unknown' from the snippet),\n",
    "# you might need to convert them to numeric first and then impute.\n",
    "# Let's try to coerce any object columns that should be numeric.\n",
    "for col in df_imputed.select_dtypes(include='object').columns:\n",
    "    # Attempt to convert to numeric, errors='coerce' will turn unparseable values into NaN\n",
    "    df_imputed[col] = pd.to_numeric(df_imputed[col], errors='coerce')\n",
    "    if df_imputed[col].isnull().any(): # Check if there are now NaNs after coercion\n",
    "         # Decide on imputation strategy for these coerced columns - mean is simple\n",
    "        if pd.api.types.is_numeric_dtype(df_imputed[col]):\n",
    "            mean_val = df_imputed[col].mean()\n",
    "            df_imputed[col] = df_imputed[col].fillna(mean_val) # Avoids the Future Warning\n",
    "        # else: # Handle non-numeric object columns if necessary, maybe with mode or a placeholder string\n",
    "            # df_imputed[col] = df_imputed[col].fillna('Missing')\n",
    "\n",
    "\n",
    "print(\"\\nMissing values per column after imputation:\")\n",
    "print(df_imputed.isnull().sum().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Display the first few rows of the imputed DataFrame to check\n",
    "print(\"\\nFirst 5 rows after imputation:\")\n",
    "print(df_imputed.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4caa89b-f833-44b9-9c7b-ef82e26ec418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original number of rows: 53\n",
      "Number of synthetic rows added: 85000\n",
      "Total number of rows in the combined dataset: 85053\n",
      "\n",
      "First 5 rows of the combined dataset:\n",
      "| Year    | Month   | Avg_Temp (°C)   | Max_Temp (°C)   | Min_Temp (°C)   | Precipitation (mm)   | Humidity (%)   | Wind_Speed (m/s)   | Solar_Irradiance (W/m²)   | Cloud_Cover (%)   | CO2_Concentration (ppm)   | Latitude   | Longitude   | Altitude (m)   | Proximity_to_Water (km)   | Urbanization_Index   | Vegetation_Index   | ENSO_Index   | Particulate_Matter (µg/m³)   | Sea_Surface_Temp (°C)   |\n",
      "|:--------|:--------|:----------------|:----------------|:----------------|:---------------------|:---------------|:-------------------|:--------------------------|:------------------|:--------------------------|:-----------|:------------|:---------------|:--------------------------|:---------------------|:-------------------|:-------------|:-----------------------------|:------------------------|\n",
      "| 2021.87 | 1       | -3.46052        | 33.0569         | 2280.9          | 184.9                | 89.6208        | 9.74289            | 173.826                   | 58.5308           | 423.476                   | 40.7128    | -74.006     | 10             | 15                        | 4000.48              | 0.0442378          | 0.633694     | 33.4371                      | 18.5454                 |\n",
      "| 2020    | 2       | 13.0187         | 25.9019         | 3.17397         | 2.95724              | 95.171         | 10.6482            | 252.314                   | 32.8567           | 419.596                   | 40.7128    | -74.006     | 10             | 15                        | 99999                | 0.61284            | 4081.67      | 24.5048                      | 15.9096                 |\n",
      "| 2020    | 3       | 7.86984         | 18.6342         | 10.4249         | 2188.91              | 67.2697        | 2008.36            | 247.391                   | 29.3802           | 416.65                    | 40.7128    | -74.006     | 10             | 15                        | 0.341732             | 0.466565           | -0.428058    | 32.3275                      | 21.2811                 |\n",
      "| 2021.87 | 4       | -0.0498626      | 13.0306         | -9.19643        | 102.454              | 67.2697        | 0.898698           | 143.262                   | 17.4969           | 418.923                   | 40.7128    | -74.006     | 10             | 15                        | 0.896383             | 0.0304659          | -0.570708    | 20.4963                      | 19.5453                 |\n",
      "| 2020    | 5       | 19.8951         | 35.8821         | 20.068          | 185.729              | 73.9999        | 13.1283            | 169.549                   | 2.19371           | 401.897                   | 40.7128    | -74.006     | 10             | 99999                     | 0.0761732            | 0.441901           | -0.286149    | 22.6491                      | 15.503                  |\n",
      "\n",
      "Last 5 rows of the combined dataset (likely synthetic):\n",
      "| Year    | Month    | Avg_Temp (°C)   | Max_Temp (°C)   | Min_Temp (°C)   | Precipitation (mm)   | Humidity (%)   | Wind_Speed (m/s)   | Solar_Irradiance (W/m²)   | Cloud_Cover (%)   | CO2_Concentration (ppm)   | Latitude   | Longitude   | Altitude (m)   | Proximity_to_Water (km)   | Urbanization_Index   | Vegetation_Index   | ENSO_Index   | Particulate_Matter (µg/m³)   | Sea_Surface_Temp (°C)   |\n",
      "|:--------|:---------|:----------------|:----------------|:----------------|:---------------------|:---------------|:-------------------|:--------------------------|:------------------|:--------------------------|:-----------|:------------|:---------------|:--------------------------|:---------------------|:-------------------|:-------------|:-----------------------------|:------------------------|\n",
      "| 2023    | 5.7816   | 3.07345         | 17.1266         | -398.946        | 13.715               | 66.4831        | -778.358           | 164.159                   | 30.2196           | 436.76                    | 2330.96    | -74.006     | 9.94461        | 2038.77                   | -5491.75             | 0.481858           | 5194.41      | 1446.36                      | 25.6207                 |\n",
      "| 2021.86 | 10.106   | 11.8992         | 30.5323         | 4716.44         | 2724.89              | 40.9127        | -1564.84           | 197.183                   | 85.1097           | 432.381                   | 5688.93    | -74.006     | 10.0284        | 925.67                    | 1.90792              | 0.227917           | -7568.54     | -1814.41                     | 10.8415                 |\n",
      "| 2021.15 | 9.4314   | 8.00671         | 23.6868         | -1945.44        | -4179.32             | 63.387         | 2054.15            | 292.456                   | 52.3654           | 401.137                   | -4711.78   | -74.006     | 10.0282        | 4634.54                   | 3493.83              | 0.609974           | 16867.2      | 12344.1                      | 19.6161                 |\n",
      "| 2022.04 | 0.834352 | 13.442          | 17.3422         | 4551.2          | -6936.32             | 54.4061        | 590.659            | 192.964                   | 27.3845           | 413.667                   | 8423.95    | -74.006     | 10.0148        | -1561.03                  | 12689.8              | 0.00905045         | 1524.47      | 6250.64                      | 12.5169                 |\n",
      "| 2021.92 | 2.70259  | 7.18321         | 33.7853         | 10320.1         | 4423.16              | 66.456         | 4026.23            | 271.663                   | 33.53             | 402.9                     | -4274.03   | -74.006     | 9.98733        | -2521.04                  | 2624.41              | 0.125687           | 7024.68      | -6990.53                     | 20.0731                 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df_imputed' is the DataFrame after handling missing values\n",
    "# Let's create a small number of synthetic data points by adding random noise to existing ones\n",
    "n_synthetic_samples = 85000 # You can adjust the number of synthetic samples to generate\n",
    "\n",
    "# Select random rows from the imputed data to create synthetic data from\n",
    "synthetic_data = df_imputed.sample(n=n_synthetic_samples, replace=True, random_state=42).copy()\n",
    "\n",
    "# Add a small amount of random noise to the numerical columns\n",
    "# The scale of the noise should be relatively small compared to the range of the data\n",
    "noise_scale = 0.05 # You can adjust this value - smaller means less noise\n",
    "\n",
    "for col in synthetic_data.select_dtypes(include=np.number).columns:\n",
    "    # Calculate the range of the column to scale the noise\n",
    "    col_range = synthetic_data[col].max() - synthetic_data[col].min()\n",
    "    if col_range == 0: # Avoid division by zero if all values are the same\n",
    "        col_range = 1\n",
    "    \n",
    "    # Generate random noise scaled by the column's range and the noise_scale\n",
    "    noise = np.random.randn(n_synthetic_samples) * col_range * noise_scale\n",
    "    \n",
    "    # Add the noise to the column\n",
    "    synthetic_data[col] = synthetic_data[col] + noise\n",
    "\n",
    "# Combine the original imputed data with the synthetic data\n",
    "df_combined = pd.concat([df_imputed, synthetic_data], ignore_index=True)\n",
    "\n",
    "print(f\"\\nOriginal number of rows: {len(df_imputed)}\")\n",
    "print(f\"Number of synthetic rows added: {n_synthetic_samples}\")\n",
    "print(f\"Total number of rows in the combined dataset: {len(df_combined)}\")\n",
    "\n",
    "# Display the first 5 rows of the combined dataset to see the original and synthetic data\n",
    "print(\"\\nFirst 5 rows of the combined dataset:\")\n",
    "print(df_combined.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Display the last 5 rows to see some of the synthetic data\n",
    "print(\"\\nLast 5 rows of the combined dataset (likely synthetic):\")\n",
    "print(df_combined.tail().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c547ab40-317a-4c87-886f-1e84d743f165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 6: Re-splitting the Combined Data ---\n",
      "\n",
      "Combined data splitting complete.\n",
      "Combined training features shape (X_train_combined): (68042, 19)\n",
      "Combined testing features shape (X_test_combined): (17011, 19)\n",
      "Combined training target shape (y_train_combined): (68042,)\n",
      "Combined testing target shape (y_test_combined): (17011,)\n",
      "\n",
      "--- Step 7: Retraining the Model on the Combined Data ---\n",
      "\n",
      "Training the Random Forest Regressor model on combined data...\n",
      "Model training on combined data complete.\n",
      "\n",
      "--- Step 8: Re-evaluating the Model on the Combined Test Data ---\n",
      "\n",
      "Making predictions on the combined test data...\n",
      "Predictions made on combined data.\n",
      "\n",
      "Model Evaluation Results (Combined Data):\n",
      "Mean Absolute Error (MAE): 9.95\n",
      "R-squared (R²): 0.97\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Re-split the Combined Data ---\n",
    "print(\"--- Step 6: Re-splitting the Combined Data ---\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd # Assuming pandas is already imported\n",
    "# Assuming df_combined is available from the previous synthetic data generation step\n",
    "\n",
    "# Define your features (X) and target (y) - Use the same ones as before\n",
    "features = ['Year', 'Month', 'Avg_Temp (°C)', 'Max_Temp (°C)', 'Min_Temp (°C)',\n",
    "            'Precipitation (mm)', 'Humidity (%)', 'Wind_Speed (m/s)',\n",
    "            'Cloud_Cover (%)', 'CO2_Concentration (ppm)', 'Latitude', 'Longitude',\n",
    "            'Altitude (m)', 'Proximity_to_Water (km)', 'Urbanization_Index',\n",
    "            'Vegetation_Index', 'ENSO_Index', 'Particulate_Matter (µg/m³)',\n",
    "            'Sea_Surface_Temp (°C)'] # Updated features based on your confirmation\n",
    "\n",
    "target = 'Solar_Irradiance (W/m²)' # Your target variable\n",
    "\n",
    "# Ensure the target column exists and features are in the combined DataFrame\n",
    "if target not in df_combined.columns:\n",
    "    print(f\"Error: Target column '{target}' not found in the combined DataFrame. Please check the column name.\")\n",
    "else:\n",
    "     # Drop any potential rows where the target is still missing (should be 0 after original imputation)\n",
    "    df_cleaned_target_combined = df_combined.dropna(subset=[target])\n",
    "\n",
    "    # Verify all selected features are in the DataFrame\n",
    "    selected_features = [f for f in features if f in df_cleaned_target_combined.columns]\n",
    "    missing_features = [f for f in features if f not in df_cleaned_target_combined.columns]\n",
    "\n",
    "    if missing_features:\n",
    "        print(f\"Warning: The following feature columns were not found in the DataFrame and will be excluded: {missing_features}\")\n",
    "\n",
    "    if not selected_features:\n",
    "        print(\"Error: No valid feature columns selected. Please check your feature list against the DataFrame columns.\")\n",
    "    else:\n",
    "        X_combined = df_cleaned_target_combined[selected_features]\n",
    "        y_combined = df_cleaned_target_combined[target]\n",
    "\n",
    "        # Split the combined data into training and testing sets\n",
    "        # We'll use 80% for training and 20% for testing, same random_state for consistency\n",
    "        X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "        print(\"\\nCombined data splitting complete.\")\n",
    "        print(f\"Combined training features shape (X_train_combined): {X_train_combined.shape}\")\n",
    "        print(f\"Combined testing features shape (X_test_combined): {X_test_combined.shape}\")\n",
    "        print(f\"Combined training target shape (y_train_combined): {y_train_combined.shape}\")\n",
    "        print(f\"Combined testing target shape (y_test_combined): {y_test_combined.shape}\")\n",
    "\n",
    "        # --- Step 7: Retrain the Model on the Combined Data ---\n",
    "        print(\"\\n--- Step 7: Retraining the Model on the Combined Data ---\")\n",
    "\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        # Assuming Random Forest Regressor model is your choice and necessary libraries are imported\n",
    "        # Assuming X_train_combined and y_train_combined are available\n",
    "\n",
    "        # Choose the Random Forest Regressor model with the same parameters\n",
    "        model_combined = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "        # Train the model using the combined training data\n",
    "        print(\"\\nTraining the Random Forest Regressor model on combined data...\")\n",
    "        model_combined.fit(X_train_combined, y_train_combined)\n",
    "        print(\"Model training on combined data complete.\")\n",
    "\n",
    "        # --- Step 8: Re-evaluate the Model on the Combined Test Data ---\n",
    "        print(\"\\n--- Step 8: Re-evaluating the Model on the Combined Test Data ---\")\n",
    "\n",
    "        from sklearn.metrics import mean_absolute_error, r2_score\n",
    "        import pandas as pd # Assuming pandas is already imported\n",
    "        # Assuming model_combined, X_test_combined, and y_test_combined are available\n",
    "\n",
    "        # Make predictions on the combined test data\n",
    "        print(\"\\nMaking predictions on the combined test data...\")\n",
    "        y_pred_combined = model_combined.predict(X_test_combined)\n",
    "        print(\"Predictions made on combined data.\")\n",
    "\n",
    "        # Evaluate the model's performance on combined data\n",
    "        mae_combined = mean_absolute_error(y_test_combined, y_pred_combined)\n",
    "        r2_combined = r2_score(y_test_combined, y_pred_combined)\n",
    "\n",
    "        print(f\"\\nModel Evaluation Results (Combined Data):\")\n",
    "        print(f\"Mean Absolute Error (MAE): {mae_combined:.2f}\")\n",
    "        print(f\"R-squared (R²): {r2_combined:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad82fef3-5e05-4e6b-8570-5cc9707a7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved to solar_potential_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming model_combined is your trained Random Forest Regressor model\n",
    "# Define a filename for your model\n",
    "model_filename = 'solar_potential_model.pkl'\n",
    "\n",
    "# Save the trained model to the file\n",
    "joblib.dump(model_combined, model_filename)\n",
    "\n",
    "print(f\"Trained model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcac10ff-8193-4c45-a44e-b343a59d489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional Model Evaluation Results:\n",
      "Mean Squared Error (MSE): 160.78\n",
      "Root Mean Squared Error (RMSE): 12.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np # Import numpy for square root\n",
    "# Assuming y_test_combined and y_pred_combined are available from the previous evaluation step\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test_combined, y_pred_combined)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"\\nAdditional Model Evaluation Results:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4ce33-c99c-4005-8b3e-f98af365a680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
